name: Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

permissions:
  contents: read
  pull-requests: write
  issues: write

env:
  NODE_VERSION: '20.x'

jobs:
  test:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    strategy:
      matrix:
        project: [backend, frontend]
      fail-fast: false

    steps:
    - name: 📦 Checkout repository
      uses: actions/checkout@v4

    - name: 🟢 Setup Node.js ${{ env.NODE_VERSION }}
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}

    - name: 🔧 Cache node modules
      uses: actions/cache@v4
      with:
        path: ${{ matrix.project }}/node_modules
        key: ${{ runner.os }}-${{ matrix.project }}-node-${{ hashFiles(format('{0}/package-lock.json', matrix.project)) }}
        restore-keys: |
          ${{ runner.os }}-${{ matrix.project }}-node-

    - name: 🔧 Install dependencies
      working-directory: './${{ matrix.project }}'
      run: |
        if [ -f package-lock.json ]; then
          # Try npm ci first, fallback to npm install if there are dependency issues
          npm ci || {
            echo "npm ci failed due to dependency conflicts, regenerating lock file..."
            rm -rf node_modules package-lock.json
            npm install
          }
        else
          npm install
        fi

    - name: 🧪 Run tests with coverage
      id: run-tests
      working-directory: './${{ matrix.project }}'
      run: |
        set +e
        npm run test:coverage 2>&1 | tee test-output.log
        TEST_EXIT_CODE=$?
        echo "test-exit-code=$TEST_EXIT_CODE" >> $GITHUB_OUTPUT
        
        # Log the exit code for debugging
        echo "Test exit code: $TEST_EXIT_CODE"
        
        # Always continue to parsing step, don't exit here
        exit 0

    - name: 📊 Parse test results
      id: test-results
      working-directory: './${{ matrix.project }}'
      run: |
        # Initialize defaults
        SUITES_PASSED="0"
        SUITES_TOTAL="0"
        TESTS_PASSED="0"
        TESTS_TOTAL="0"
        COVERAGE="Unknown"
        TEST_EXIT_CODE="${{ steps.run-tests.outputs.test-exit-code }}"
        
        echo "=== Parsing test output ==="
        echo "Original test exit code: $TEST_EXIT_CODE"
        cat test-output.log
        echo "=== End of test output ==="
        
        # Parse test suites - Jest format: "Test Suites: X passed, Y total" or "Test Suites: X failed, Y passed, Z total"
        SUITES_FAILED=0
        if grep -q "Test Suites:" test-output.log; then
          SUITES_LINE=$(grep "Test Suites:" test-output.log | tail -1)
          echo "Suites line: $SUITES_LINE"
          
          # Extract failed suites first (format: "X failed")
          SUITES_FAILED=$(echo "$SUITES_LINE" | grep -o '[0-9]\+ failed' | grep -o '[0-9]\+' | head -1)
          SUITES_FAILED=${SUITES_FAILED:-0}
          
          # Extract passed suites (format: "X passed")
          SUITES_PASSED=$(echo "$SUITES_LINE" | grep -o '[0-9]\+ passed' | grep -o '[0-9]\+' | head -1)
          
          # Extract total suites (format: "Y total")
          SUITES_TOTAL=$(echo "$SUITES_LINE" | grep -o '[0-9]\+ total' | grep -o '[0-9]\+' | head -1)
        fi
        
        # Parse individual tests - Jest format: "Tests: X passed, Y total" or "Tests: X failed, Y passed, Z total"
        TESTS_FAILED=0
        if grep -q "Tests:" test-output.log; then
          TESTS_LINE=$(grep "Tests:" test-output.log | tail -1)
          echo "Tests line: $TESTS_LINE"
          
          # Extract failed tests first (format: "X failed")
          TESTS_FAILED=$(echo "$TESTS_LINE" | grep -o '[0-9]\+ failed' | grep -o '[0-9]\+' | head -1)
          TESTS_FAILED=${TESTS_FAILED:-0}
          
          # Extract passed tests (format: "X passed")
          TESTS_PASSED=$(echo "$TESTS_LINE" | grep -o '[0-9]\+ passed' | grep -o '[0-9]\+' | head -1)
          
          # Extract total tests (format: "Y total")
          TESTS_TOTAL=$(echo "$TESTS_LINE" | grep -o '[0-9]\+ total' | grep -o '[0-9]\+' | head -1)
        fi
        
        # Parse coverage
        if grep -q "All files" test-output.log; then
          COVERAGE_LINE=$(grep "All files" test-output.log | head -1)
          COVERAGE_NUM=$(echo "$COVERAGE_LINE" | awk '{print $4}' | head -1)
          if [[ "$COVERAGE_NUM" =~ ^[0-9]+\.?[0-9]*$ ]]; then
            COVERAGE="${COVERAGE_NUM}%"
          fi
        fi
        
        # Set defaults if parsing failed
        SUITES_PASSED=${SUITES_PASSED:-"0"}
        SUITES_TOTAL=${SUITES_TOTAL:-"0"}
        TESTS_PASSED=${TESTS_PASSED:-"0"}
        TESTS_TOTAL=${TESTS_TOTAL:-"0"}
        
        echo "Parsed results:"
        echo "  Suites: $SUITES_PASSED/$SUITES_TOTAL (${SUITES_FAILED} failed)"
        echo "  Tests: $TESTS_PASSED/$TESTS_TOTAL (${TESTS_FAILED} failed)"
        echo "  Coverage: $COVERAGE"
        echo "  Exit code: $TEST_EXIT_CODE"
        
        # Determine status - multiple failure conditions
        FAILURE_DETECTED=false
        
        # Primary check: exit code (most reliable)
        if [ "$TEST_EXIT_CODE" != "0" ]; then
          echo "❌ Failure detected: Non-zero exit code ($TEST_EXIT_CODE)"
          FAILURE_DETECTED=true
        fi
        
        # Direct failure count checks (most reliable for Jest)
        if [ "$TESTS_FAILED" -gt "0" ]; then
          echo "❌ Failure detected: $TESTS_FAILED test(s) failed"
          FAILURE_DETECTED=true
        fi
        
        if [ "$SUITES_FAILED" -gt "0" ]; then
          echo "❌ Failure detected: $SUITES_FAILED test suite(s) failed"
          FAILURE_DETECTED=true
        fi
        
        # Fallback checks: if we couldn't parse failure counts, check totals vs passed
        if [ "$TESTS_FAILED" = "0" ] && [ -n "$TESTS_TOTAL" ] && [ "$TESTS_TOTAL" -gt "0" ] && [ -n "$TESTS_PASSED" ]; then
          if [ "$TESTS_PASSED" -lt "$TESTS_TOTAL" ]; then
            echo "❌ Failure detected: Not all tests passed ($TESTS_PASSED/$TESTS_TOTAL)"
            FAILURE_DETECTED=true
          fi
        fi
        
        if [ "$SUITES_FAILED" = "0" ] && [ -n "$SUITES_TOTAL" ] && [ "$SUITES_TOTAL" -gt "0" ] && [ -n "$SUITES_PASSED" ]; then
          if [ "$SUITES_PASSED" -lt "$SUITES_TOTAL" ]; then
            echo "❌ Failure detected: Not all suites passed ($SUITES_PASSED/$SUITES_TOTAL)"
            FAILURE_DETECTED=true
          fi
        fi
        
        # Check for specific failure keywords (but exclude common false positives)
        # Only check for explicit test failures, not console.error or other logging
        if grep -q -E "([0-9]+ failed|FAIL:|Test failed|Failed to|× )" test-output.log; then
          # Double check this isn't just console.error or expected error logging
          if ! (grep -q "console\.error" test-output.log && [ "$TEST_EXIT_CODE" = "0" ]); then
            echo "❌ Failure detected: Failure keywords found in output"
            FAILURE_DETECTED=true
          else
            echo "ℹ️  Found error keywords but they appear to be console.error logs (exit code is 0)"
          fi
        fi
        
        # Set final status
        if [ "$FAILURE_DETECTED" = true ]; then
          TEST_STATUS="❌ Some tests failed"
          EXIT_CODE=1
        else
          TEST_STATUS="✅ All tests passed"
          EXIT_CODE=0
        fi
        
        echo "Final status: $TEST_STATUS (exit code: $EXIT_CODE)"
        
        # Export results
        echo "suites-passed=$SUITES_PASSED" >> $GITHUB_OUTPUT
        echo "suites-total=$SUITES_TOTAL" >> $GITHUB_OUTPUT
        echo "tests-passed=$TESTS_PASSED" >> $GITHUB_OUTPUT
        echo "tests-total=$TESTS_TOTAL" >> $GITHUB_OUTPUT
        echo "coverage=$COVERAGE" >> $GITHUB_OUTPUT
        echo "status=$TEST_STATUS" >> $GITHUB_OUTPUT
        echo "exit-code=$EXIT_CODE" >> $GITHUB_OUTPUT
        echo "project=${{ matrix.project }}" >> $GITHUB_OUTPUT

    - name: 📋 Generate test summary
      if: always()
      run: |
        echo "## 🧪 ${{ matrix.project }} Test Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Metric | Result |" >> $GITHUB_STEP_SUMMARY
        echo "|--------|--------|" >> $GITHUB_STEP_SUMMARY
        echo "| **Status** | ${{ steps.test-results.outputs.status }} |" >> $GITHUB_STEP_SUMMARY
        echo "| **Test Suites** | ${{ steps.test-results.outputs.suites-passed }}/${{ steps.test-results.outputs.suites-total }} passed |" >> $GITHUB_STEP_SUMMARY
        echo "| **Individual Tests** | ${{ steps.test-results.outputs.tests-passed }}/${{ steps.test-results.outputs.tests-total }} passed |" >> $GITHUB_STEP_SUMMARY
        echo "| **Coverage** | ${{ steps.test-results.outputs.coverage }} |" >> $GITHUB_STEP_SUMMARY
        echo "| **Original Exit Code** | ${{ steps.run-tests.outputs.test-exit-code }} |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

    - name: 📊 Upload coverage reports
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: coverage-report-${{ matrix.project }}-${{ github.run_number }}
        path: '${{ matrix.project }}/coverage/'
        retention-days: 30

    - name: 💾 Store test results
      if: always()
      run: |
        mkdir -p /tmp/test-results
        echo "${{ steps.test-results.outputs.project }}|${{ steps.test-results.outputs.status }}|${{ steps.test-results.outputs.suites-passed }}|${{ steps.test-results.outputs.suites-total }}|${{ steps.test-results.outputs.tests-passed }}|${{ steps.test-results.outputs.tests-total }}|${{ steps.test-results.outputs.coverage }}|${{ steps.test-results.outputs.exit-code }}" > /tmp/test-results/${{ matrix.project }}.txt

    - name: 📤 Upload test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: test-results-${{ matrix.project }}
        path: /tmp/test-results/
        retention-days: 1

    - name: ❌ Fail if tests failed
      if: steps.test-results.outputs.exit-code != '0'
      run: |
        echo "❌ Tests failed for ${{ matrix.project }}!"
        echo "Status: ${{ steps.test-results.outputs.status }}"
        echo "Tests: ${{ steps.test-results.outputs.tests-passed }}/${{ steps.test-results.outputs.tests-total }}"
        echo "Suites: ${{ steps.test-results.outputs.suites-passed }}/${{ steps.test-results.outputs.suites-total }}"
        echo "Original exit code: ${{ steps.run-tests.outputs.test-exit-code }}"
        exit 1

  cypress:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    env:
      NODE_VERSION: '20.x'
    steps:
      - name: 📦 Checkout repository
        uses: actions/checkout@v4

      - name: 🟢 Setup Node.js ${{ env.NODE_VERSION }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: 🔧 Install backend dependencies
        working-directory: ./backend
        run: |
          if [ -f package-lock.json ]; then
            # Try npm ci first, fallback to npm install if there are dependency issues
            npm ci || {
              echo "npm ci failed due to dependency conflicts, regenerating lock file..."
              rm -rf node_modules package-lock.json
              npm install
            }
          else
            npm install
          fi

      - name: 🔧 Install frontend dependencies
        working-directory: ./frontend
        run: |
          if [ -f package-lock.json ]; then
            # Try npm ci first, fallback to npm install if there are dependency issues
            npm ci || {
              echo "npm ci failed due to dependency conflicts, regenerating lock file..."
              rm -rf node_modules package-lock.json
              npm install
            }
          else
            npm install
          fi

      - name: 🔧 Force SQLite for CI tests
        working-directory: ./backend
        run: |
          # This command replaces 'postgresql' with 'sqlite' to ensure CI uses SQLite.
          sed -i 's/provider = "postgresql"/provider = "sqlite"/' prisma/schema.prisma
          echo "✅ Prisma schema has been configured for SQLite."

      - name: 🗄️ Setup database
        working-directory: ./backend
        env:
          DATABASE_URL: file:./test.db
        run: |
          echo "🗄️ Setting up database..."
          npx prisma generate
          echo "✅ Prisma client generated"
          npx prisma db push
          echo "✅ Database schema applied"
          
          # Check if database file was created
          if [ -f "prisma/test.db" ]; then
            echo "✅ Database file created (prisma/test.db)"
          else
            echo "❌ Database file not found"
            exit 1
          fi
          
          echo "🌱 Running seed script..."
          npm run seed 2>&1 | tee seed.log || {
            echo "⚠️ Seeding failed, continuing without seed data"
          }
          echo "✅ Database setup completed"

      - name: 🚀 Start backend server
        working-directory: ./backend
        env:
          DATABASE_URL: file:./test.db
          PORT: 8000
          NODE_ENV: development
        run: |
          echo "🚀 Starting backend server on port 8000..."
          
          # Start server in background and capture PID
          npm start > server.log 2>&1 &
          BACKEND_PID=$!
          echo "Backend PID: $BACKEND_PID"
          echo "BACKEND_PID=$BACKEND_PID" >> $GITHUB_ENV
          
          sleep 5
          if kill -0 $BACKEND_PID 2>/dev/null; then
            echo "✅ Backend process running"
          else
            echo "❌ Backend process crashed (see server.log)"
            cat server.log
            exit 1
          fi

      - name: 🔍 Verify services are running
        run: |
          echo "🔍 Verifying backend health..."
          for i in {1..10}; do
            if curl -sSf http://localhost:8000/products > /dev/null; then
              echo "✅ Backend healthy"
              break
            elif [ $i -eq 10 ]; then
              echo "❌ Backend health check failed"
              cat backend/server.log || true
              exit 1
            else
              sleep 3
            fi
          done
          echo "🟢 Backend ready"

      - name: 🧪 Run Cypress tests with local services
        id: cypress-run
        run: |
          cd frontend
          
          # Start frontend in background
          npm start &
          FRONTEND_PID=$!
          echo "FRONTEND_PID=$FRONTEND_PID" >> $GITHUB_ENV
          
          # Wait for both services to be ready
          echo "🔄 Waiting for services to be ready..."
          timeout 180 bash -c 'until curl -f http://localhost:3000 > /dev/null 2>&1; do echo "Waiting for frontend..."; sleep 2; done' || { echo "❌ Frontend timeout"; exit 1; }
          timeout 30 bash -c 'until curl -f http://localhost:8000/products > /dev/null 2>&1; do echo "Waiting for backend..."; sleep 2; done' || { echo "❌ Backend timeout"; exit 1; }
          
          echo "🟢 Services ready, running Cypress tests..."
          
          # Run Cypress and capture output
          npm run test:e2e > cypress_output.log 2>&1
          CYPRESS_EXIT_CODE=$?
          
          # Stop frontend
          kill $FRONTEND_PID 2>/dev/null || echo "Frontend already stopped"
          
          # Display the output
          cat cypress_output.log
          
          # Extract numbers from "Tests:", "Passing:", "Failing:" lines (works for both pass & fail; skips ANSI codes)
          TOTAL_TESTS=$(grep -oE "Tests:[[:space:]]+[0-9]+" cypress_output.log | awk '{sum+=$2} END {print sum+0}')
          PASSED_TESTS=$(grep -oE "Passing:[[:space:]]+[0-9]+" cypress_output.log | awk '{sum+=$2} END {print sum+0}')
          FAILED_TESTS=$(grep -oE "Failing:[[:space:]]+[0-9]+" cypress_output.log | awk '{sum+=$2} END {print sum+0}')

          if [ $CYPRESS_EXIT_CODE -eq 0 ]; then
            echo "CYPRESS_STATUS=success" >> $GITHUB_OUTPUT
          else
            echo "CYPRESS_STATUS=failure" >> $GITHUB_OUTPUT
          fi

          echo "CYPRESS_TOTAL=$TOTAL_TESTS" >> $GITHUB_OUTPUT
          echo "CYPRESS_PASSED=$PASSED_TESTS" >> $GITHUB_OUTPUT
          echo "CYPRESS_FAILED=$FAILED_TESTS" >> $GITHUB_OUTPUT
          
          exit $CYPRESS_EXIT_CODE
        env:
          CYPRESS_BASE_URL: http://localhost:3000
          CYPRESS_API_URL: http://localhost:8000

      - name: 📋 Debug information on failure
        if: failure()
        run: |
          echo "🔍 Collecting debug information..."
          echo "=== Backend Logs ==="
          cat backend/server.log || echo "No backend logs found"
          echo ""
          echo "=== Seed Logs ==="
          cat backend/seed.log || echo "No seed logs found"
          echo ""
          echo "=== Process List ==="
          ps aux | grep -E "(node|npm)" || echo "No Node processes found"
          echo ""
          echo "=== Port Usage ==="
          netstat -tlnp 2>/dev/null | grep -E "(3000|8000)" || echo "Ports 3000/8000 not in use"
          echo ""
          echo "=== Database File ==="
          ls -la backend/test.db || echo "Database file not found"

      - name: 🛑 Stop backend server
        if: always()
        run: |
          if [ -n "$BACKEND_PID" ]; then
            echo "🛑 Stopping backend server (PID: $BACKEND_PID)"
            kill $BACKEND_PID 2>/dev/null || echo "Backend already stopped"
            # Wait a moment for graceful shutdown
            sleep 2
            # Force kill if still running
            kill -9 $BACKEND_PID 2>/dev/null || echo "Backend process cleaned up"
          fi
          
          # Also stop any remaining frontend processes
          if [ -n "$FRONTEND_PID" ]; then
            echo "🛑 Stopping frontend server (PID: $FRONTEND_PID)"
            kill $FRONTEND_PID 2>/dev/null || echo "Frontend already stopped"
            kill -9 $FRONTEND_PID 2>/dev/null || echo "Frontend process cleaned up"
          fi

      - name: 💾 Store Cypress results
        if: always()
        run: |
          mkdir -p /tmp/test-results
          STATUS="❌ Failed"
          EXIT_CODE=1
          PASSED="${{ steps.cypress-run.outputs.CYPRESS_PASSED }}"
          FAILED="${{ steps.cypress-run.outputs.CYPRESS_FAILED }}"
          TOTAL="${{ steps.cypress-run.outputs.CYPRESS_TOTAL }}"
          
          # Set defaults if values are empty
          if [ "${PASSED}" = "" ]; then PASSED="0"; fi
          if [ "${FAILED}" = "" ]; then FAILED="0"; fi  
          if [ "${TOTAL}" = "" ]; then TOTAL="0"; fi
          
          if [ "${{ steps.cypress-run.outcome }}" = "success" ]; then
            STATUS="✅ Passed"
            EXIT_CODE=0
          fi
          
          # Format: project|status|suites_passed|suites_total|tests_passed|tests_total|coverage|exit_code
          echo "cypress|$STATUS|8|8|${PASSED}|${TOTAL}|N/A|$EXIT_CODE" > /tmp/test-results/cypress.txt

      - name: 📤 Upload Cypress results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-cypress
          path: /tmp/test-results/
          retention-days: 1

      - name: 📋 Generate test summary
        if: always()
        run: |
          PASSED="${{ steps.cypress-run.outputs.CYPRESS_PASSED }}"
          FAILED="${{ steps.cypress-run.outputs.CYPRESS_FAILED }}"
          TOTAL="${{ steps.cypress-run.outputs.CYPRESS_TOTAL }}"
          
          # Set defaults if values are empty
          if [ "${PASSED}" = "" ]; then PASSED="0"; fi
          if [ "${FAILED}" = "" ]; then FAILED="0"; fi  
          if [ "${TOTAL}" = "" ]; then TOTAL="0"; fi
          
          echo "## 🧪 Cypress E2E Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Result |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|--------|" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ steps.cypress-run.outcome }}" = "success" ]; then
            echo "| **Status** | ✅ All tests passed |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| **Status** | ❌ Some tests failed |" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "| **Total Tests** | ${TOTAL} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Passed** | ${PASSED} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Failed** | ${FAILED} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Success Rate** | $(echo "scale=1; ${PASSED} * 100 / ${TOTAL}" | bc -l 2>/dev/null || echo "100")% |" >> $GITHUB_STEP_SUMMARY
          echo "| **Job Outcome** | ${{ steps.cypress-run.outcome }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

      - name: ❌ Fail job if Cypress tests failed
        if: steps.cypress-run.outcome != 'success'
        run: |
          echo "❌ Cypress tests failed!"
          echo "Outcome: ${{ steps.cypress-run.outcome }}"
          exit 1

  test-summary:
    runs-on: ubuntu-latest
    needs: [test, cypress]
    if: always() && github.event_name == 'pull_request'
    steps:
    - name: 📥 Download test results
      uses: actions/download-artifact@v4
      with:
        pattern: test-results-*
        merge-multiple: true
        path: /tmp/test-results

    - name: 📝 Collect test results
      id: collect-results
      run: |
        BACKEND_STATUS="❌ Failed"
        FRONTEND_STATUS="❌ Failed"
        CYPRESS_STATUS="❌ Failed"
        BACKEND_DETAILS="Not run"
        FRONTEND_DETAILS="Not run"
        CYPRESS_DETAILS="Not run"
        OVERALL_SUCCESS=true
        
        if [ -f "/tmp/test-results/backend.txt" ]; then
          BACKEND_DATA=$(cat /tmp/test-results/backend.txt)
          IFS='|' read -r PROJECT STATUS SUITES_PASSED SUITES_TOTAL TESTS_PASSED TESTS_TOTAL COVERAGE EXIT_CODE <<< "$BACKEND_DATA"
          if [ "$EXIT_CODE" = "0" ]; then
            BACKEND_STATUS="✅ Passed"
          else
            OVERALL_SUCCESS=false
          fi
          BACKEND_DETAILS="$TESTS_PASSED/$TESTS_TOTAL tests, $SUITES_PASSED/$SUITES_TOTAL suites, $COVERAGE coverage"
        else
          OVERALL_SUCCESS=false
        fi
        
        if [ -f "/tmp/test-results/frontend.txt" ]; then
          FRONTEND_DATA=$(cat /tmp/test-results/frontend.txt)
          IFS='|' read -r PROJECT STATUS SUITES_PASSED SUITES_TOTAL TESTS_PASSED TESTS_TOTAL COVERAGE EXIT_CODE <<< "$FRONTEND_DATA"
          if [ "$EXIT_CODE" = "0" ]; then
            FRONTEND_STATUS="✅ Passed"
          else
            OVERALL_SUCCESS=false
          fi
          FRONTEND_DETAILS="$TESTS_PASSED/$TESTS_TOTAL tests, $SUITES_PASSED/$SUITES_TOTAL suites, $COVERAGE coverage"
        else
          OVERALL_SUCCESS=false
        fi
        
        if [ -f "/tmp/test-results/cypress.txt" ]; then
          CYPRESS_DATA=$(cat /tmp/test-results/cypress.txt)
          IFS='|' read -r PROJECT STATUS SUITES_PASSED SUITES_TOTAL TESTS_PASSED TESTS_TOTAL COVERAGE EXIT_CODE <<< "$CYPRESS_DATA"
          if [ "$EXIT_CODE" = "0" ]; then
            CYPRESS_STATUS="✅ Passed"
          else
            OVERALL_SUCCESS=false
          fi
          CYPRESS_DETAILS="$TESTS_PASSED/$TESTS_TOTAL tests, $SUITES_PASSED/$SUITES_TOTAL specs"
        else
          OVERALL_SUCCESS=false
        fi
        
        if [ "$OVERALL_SUCCESS" = true ]; then
          OVERALL_STATUS="✅ All projects passed"
        else
          OVERALL_STATUS="❌ Some projects failed"
        fi
        
        echo "overall-status=$OVERALL_STATUS" >> $GITHUB_OUTPUT
        echo "backend-status=$BACKEND_STATUS" >> $GITHUB_OUTPUT
        echo "frontend-status=$FRONTEND_STATUS" >> $GITHUB_OUTPUT
        echo "cypress-status=$CYPRESS_STATUS" >> $GITHUB_OUTPUT
        echo "backend-details=$BACKEND_DETAILS" >> $GITHUB_OUTPUT
        echo "frontend-details=$FRONTEND_DETAILS" >> $GITHUB_OUTPUT
        echo "cypress-details=$CYPRESS_DETAILS" >> $GITHUB_OUTPUT

    - name: 💬 Comment on PR
      uses: actions/github-script@v7
      continue-on-error: true
      with:
        script: |
          try {
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const botComment = comments.find(comment => 
              comment.user.type === 'Bot' && comment.body.includes('🧪 Test Results Summary')
            );
            
            const body = `## 🧪 Test Results Summary
            
            ${{ steps.collect-results.outputs.overall-status }}
            
            ### 📊 Project Results
            
            | Project | Status | Details |
            |---------|--------|---------|
            | **Backend** | ${{ steps.collect-results.outputs.backend-status }} | ${{ steps.collect-results.outputs.backend-details }} |
            | **Frontend** | ${{ steps.collect-results.outputs.frontend-status }} | ${{ steps.collect-results.outputs.frontend-details }} |
            | **Cypress E2E** | ${{ steps.collect-results.outputs.cypress-status }} | ${{ steps.collect-results.outputs.cypress-details }} |
            
            ### 📋 Coverage Reports
            - 📊 **Backend Coverage**: [Download Report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
            - 📊 **Frontend Coverage**: [Download Report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
            - 🎥 **Cypress Videos**: [Workflow Artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
            
            > 💡 **Tip**: Click on the individual job details in the [Actions tab](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}) to see detailed test results for each project.
            
            ---
            *Updated at: ${new Date().toISOString()}*`;
            
            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: body
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body
              });
            }
          } catch (error) {
            console.log('Could not comment on PR due to permissions. Results available in job summary.');
            console.log('Error:', error.message);
          } 
