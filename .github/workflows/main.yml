name: Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

permissions:
  contents: read
  pull-requests: write
  issues: write

env:
  NODE_VERSION: '20.x'

jobs:
  test:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    strategy:
      matrix:
        project: [backend, frontend]
      fail-fast: false

    steps:
    - name: 📦 Checkout repository
      uses: actions/checkout@v4

    - name: 🟢 Setup Node.js ${{ env.NODE_VERSION }}
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}

    - name: 🔧 Cache node modules
      uses: actions/cache@v4
      with:
        path: ${{ matrix.project }}/node_modules
        key: ${{ runner.os }}-${{ matrix.project }}-node-${{ hashFiles(format('{0}/package-lock.json', matrix.project)) }}
        restore-keys: |
          ${{ runner.os }}-${{ matrix.project }}-node-

    - name: 🔧 Install dependencies
      working-directory: './${{ matrix.project }}'
      run: |
        if [ -f package-lock.json ]; then
          # Try npm ci first, fallback to npm install if there are dependency issues
          npm ci || {
            echo "npm ci failed due to dependency conflicts, regenerating lock file..."
            rm -rf node_modules package-lock.json
            npm install
          }
        else
          npm install
        fi

    - name: 🧪 Run tests with coverage
      id: run-tests
      working-directory: './${{ matrix.project }}'
      run: |
        set +e
        npm run test:coverage 2>&1 | tee test-output.log
        TEST_EXIT_CODE=$?
        echo "test-exit-code=$TEST_EXIT_CODE" >> $GITHUB_OUTPUT
        
        # Log the exit code for debugging
        echo "Test exit code: $TEST_EXIT_CODE"
        
        # Always continue to parsing step, don't exit here
        exit 0

    - name: 📊 Parse test results
      id: test-results
      working-directory: './${{ matrix.project }}'
      run: |
        # Initialize defaults
        SUITES_PASSED="0"
        SUITES_TOTAL="0"
        TESTS_PASSED="0"
        TESTS_TOTAL="0"
        COVERAGE="Unknown"
        TEST_EXIT_CODE="${{ steps.run-tests.outputs.test-exit-code }}"
        
        echo "=== Parsing test output ==="
        echo "Original test exit code: $TEST_EXIT_CODE"
        cat test-output.log
        echo "=== End of test output ==="
        
        # Parse test suites - Jest format: "Test Suites: X passed, Y total"
        if grep -q "Test Suites:" test-output.log; then
          SUITES_LINE=$(grep "Test Suites:" test-output.log | tail -1)
          echo "Suites line: $SUITES_LINE"
          
          # Extract passed suites (format: "X passed")
          SUITES_PASSED=$(echo "$SUITES_LINE" | grep -o '[0-9]\+ passed' | grep -o '[0-9]\+' | head -1)
          
          # Extract total suites (format: "Y total")
          SUITES_TOTAL=$(echo "$SUITES_LINE" | grep -o '[0-9]\+ total' | grep -o '[0-9]\+' | head -1)
        fi
        
        # Parse individual tests - Jest format: "Tests: X passed, Y total"
        if grep -q "Tests:" test-output.log; then
          TESTS_LINE=$(grep "Tests:" test-output.log | tail -1)
          echo "Tests line: $TESTS_LINE"
          
          # Extract passed tests (format: "X passed")
          TESTS_PASSED=$(echo "$TESTS_LINE" | grep -o '[0-9]\+ passed' | grep -o '[0-9]\+' | head -1)
          
          # Extract total tests (format: "Y total")
          TESTS_TOTAL=$(echo "$TESTS_LINE" | grep -o '[0-9]\+ total' | grep -o '[0-9]\+' | head -1)
        fi
        
        # Parse coverage
        if grep -q "All files" test-output.log; then
          COVERAGE_LINE=$(grep "All files" test-output.log | head -1)
          COVERAGE_NUM=$(echo "$COVERAGE_LINE" | awk '{print $4}' | head -1)
          if [[ "$COVERAGE_NUM" =~ ^[0-9]+\.?[0-9]*$ ]]; then
            COVERAGE="${COVERAGE_NUM}%"
          fi
        fi
        
        # Set defaults if parsing failed
        SUITES_PASSED=${SUITES_PASSED:-"0"}
        SUITES_TOTAL=${SUITES_TOTAL:-"0"}
        TESTS_PASSED=${TESTS_PASSED:-"0"}
        TESTS_TOTAL=${TESTS_TOTAL:-"0"}
        
        echo "Parsed results:"
        echo "  Suites: $SUITES_PASSED/$SUITES_TOTAL"
        echo "  Tests: $TESTS_PASSED/$TESTS_TOTAL"
        echo "  Coverage: $COVERAGE"
        echo "  Exit code: $TEST_EXIT_CODE"
        
        # Determine status - multiple failure conditions
        FAILURE_DETECTED=false
        
        # Primary check: exit code (most reliable)
        if [ "$TEST_EXIT_CODE" != "0" ]; then
          echo "❌ Failure detected: Non-zero exit code ($TEST_EXIT_CODE)"
          FAILURE_DETECTED=true
        fi
        
        # Secondary checks only if we have valid parsing results
        if [ -n "$TESTS_TOTAL" ] && [ "$TESTS_TOTAL" -gt "0" ] && [ -n "$TESTS_PASSED" ]; then
          if [ "$TESTS_PASSED" -lt "$TESTS_TOTAL" ]; then
            echo "❌ Failure detected: Not all tests passed ($TESTS_PASSED/$TESTS_TOTAL)"
            FAILURE_DETECTED=true
          fi
        fi
        
        if [ -n "$SUITES_TOTAL" ] && [ "$SUITES_TOTAL" -gt "0" ] && [ -n "$SUITES_PASSED" ]; then
          if [ "$SUITES_PASSED" -lt "$SUITES_TOTAL" ]; then
            echo "❌ Failure detected: Not all suites passed ($SUITES_PASSED/$SUITES_TOTAL)"
            FAILURE_DETECTED=true
          fi
        fi
        
        # Check for specific failure keywords (but exclude common false positives)
        if grep -q -E "([0-9]+ failed|FAIL:|Test failed|Error:|ERROR:|Failed to)" test-output.log; then
          echo "❌ Failure detected: Failure keywords found in output"
          FAILURE_DETECTED=true
        fi
        
        # Set final status
        if [ "$FAILURE_DETECTED" = true ]; then
          TEST_STATUS="❌ Some tests failed"
          EXIT_CODE=1
        else
          TEST_STATUS="✅ All tests passed"
          EXIT_CODE=0
        fi
        
        echo "Final status: $TEST_STATUS (exit code: $EXIT_CODE)"
        
        # Export results
        echo "suites-passed=$SUITES_PASSED" >> $GITHUB_OUTPUT
        echo "suites-total=$SUITES_TOTAL" >> $GITHUB_OUTPUT
        echo "tests-passed=$TESTS_PASSED" >> $GITHUB_OUTPUT
        echo "tests-total=$TESTS_TOTAL" >> $GITHUB_OUTPUT
        echo "coverage=$COVERAGE" >> $GITHUB_OUTPUT
        echo "status=$TEST_STATUS" >> $GITHUB_OUTPUT
        echo "exit-code=$EXIT_CODE" >> $GITHUB_OUTPUT
        echo "project=${{ matrix.project }}" >> $GITHUB_OUTPUT

    - name: 📋 Generate test summary
      if: always()
      run: |
        echo "## 🧪 ${{ matrix.project }} Test Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Metric | Result |" >> $GITHUB_STEP_SUMMARY
        echo "|--------|--------|" >> $GITHUB_STEP_SUMMARY
        echo "| **Status** | ${{ steps.test-results.outputs.status }} |" >> $GITHUB_STEP_SUMMARY
        echo "| **Test Suites** | ${{ steps.test-results.outputs.suites-passed }}/${{ steps.test-results.outputs.suites-total }} passed |" >> $GITHUB_STEP_SUMMARY
        echo "| **Individual Tests** | ${{ steps.test-results.outputs.tests-passed }}/${{ steps.test-results.outputs.tests-total }} passed |" >> $GITHUB_STEP_SUMMARY
        echo "| **Coverage** | ${{ steps.test-results.outputs.coverage }} |" >> $GITHUB_STEP_SUMMARY
        echo "| **Original Exit Code** | ${{ steps.run-tests.outputs.test-exit-code }} |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

    - name: 📊 Upload coverage reports
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: coverage-report-${{ matrix.project }}-${{ github.run_number }}
        path: '${{ matrix.project }}/coverage/'
        retention-days: 30

    - name: 💾 Store test results
      if: always()
      run: |
        mkdir -p /tmp/test-results
        echo "${{ steps.test-results.outputs.project }}|${{ steps.test-results.outputs.status }}|${{ steps.test-results.outputs.suites-passed }}|${{ steps.test-results.outputs.suites-total }}|${{ steps.test-results.outputs.tests-passed }}|${{ steps.test-results.outputs.tests-total }}|${{ steps.test-results.outputs.coverage }}|${{ steps.test-results.outputs.exit-code }}" > /tmp/test-results/${{ matrix.project }}.txt

    - name: 📤 Upload test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: test-results-${{ matrix.project }}
        path: /tmp/test-results/
        retention-days: 1

    - name: ❌ Fail if tests failed
      if: steps.test-results.outputs.exit-code != '0'
      run: |
        echo "❌ Tests failed for ${{ matrix.project }}!"
        echo "Status: ${{ steps.test-results.outputs.status }}"
        echo "Tests: ${{ steps.test-results.outputs.tests-passed }}/${{ steps.test-results.outputs.tests-total }}"
        echo "Suites: ${{ steps.test-results.outputs.suites-passed }}/${{ steps.test-results.outputs.suites-total }}"
        echo "Original exit code: ${{ steps.run-tests.outputs.test-exit-code }}"
        exit 1

  test-summary:
    runs-on: ubuntu-latest
    needs: test
    if: always() && github.event_name == 'pull_request'
    steps:
    - name: 📥 Download test results
      uses: actions/download-artifact@v4
      with:
        pattern: test-results-*
        merge-multiple: true
        path: /tmp/test-results

    - name: 📝 Collect test results
      id: collect-results
      run: |
        BACKEND_STATUS="❌ Failed"
        FRONTEND_STATUS="❌ Failed"
        BACKEND_DETAILS="Not run"
        FRONTEND_DETAILS="Not run"
        OVERALL_SUCCESS=true
        
        if [ -f "/tmp/test-results/backend.txt" ]; then
          BACKEND_DATA=$(cat /tmp/test-results/backend.txt)
          IFS='|' read -r PROJECT STATUS SUITES_PASSED SUITES_TOTAL TESTS_PASSED TESTS_TOTAL COVERAGE EXIT_CODE <<< "$BACKEND_DATA"
          if [ "$EXIT_CODE" = "0" ]; then
            BACKEND_STATUS="✅ Passed"
          else
            OVERALL_SUCCESS=false
          fi
          BACKEND_DETAILS="$TESTS_PASSED/$TESTS_TOTAL tests, $SUITES_PASSED/$SUITES_TOTAL suites, $COVERAGE coverage"
        else
          OVERALL_SUCCESS=false
        fi
        
        if [ -f "/tmp/test-results/frontend.txt" ]; then
          FRONTEND_DATA=$(cat /tmp/test-results/frontend.txt)
          IFS='|' read -r PROJECT STATUS SUITES_PASSED SUITES_TOTAL TESTS_PASSED TESTS_TOTAL COVERAGE EXIT_CODE <<< "$FRONTEND_DATA"
          if [ "$EXIT_CODE" = "0" ]; then
            FRONTEND_STATUS="✅ Passed"
          else
            OVERALL_SUCCESS=false
          fi
          FRONTEND_DETAILS="$TESTS_PASSED/$TESTS_TOTAL tests, $SUITES_PASSED/$SUITES_TOTAL suites, $COVERAGE coverage"
        else
          OVERALL_SUCCESS=false
        fi
        
        if [ "$OVERALL_SUCCESS" = true ]; then
          OVERALL_STATUS="✅ All projects passed"
        else
          OVERALL_STATUS="❌ Some projects failed"
        fi
        
        echo "overall-status=$OVERALL_STATUS" >> $GITHUB_OUTPUT
        echo "backend-status=$BACKEND_STATUS" >> $GITHUB_OUTPUT
        echo "frontend-status=$FRONTEND_STATUS" >> $GITHUB_OUTPUT
        echo "backend-details=$BACKEND_DETAILS" >> $GITHUB_OUTPUT
        echo "frontend-details=$FRONTEND_DETAILS" >> $GITHUB_OUTPUT

    - name: 💬 Comment on PR
      uses: actions/github-script@v7
      continue-on-error: true
      with:
        script: |
          try {
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const botComment = comments.find(comment => 
              comment.user.type === 'Bot' && comment.body.includes('🧪 Test Results Summary')
            );
            
            const body = `## 🧪 Test Results Summary
            
            ${{ steps.collect-results.outputs.overall-status }}
            
            ### 📊 Project Results
            
            | Project | Status | Details |
            |---------|--------|---------|
            | **Backend** | ${{ steps.collect-results.outputs.backend-status }} | ${{ steps.collect-results.outputs.backend-details }} |
            | **Frontend** | ${{ steps.collect-results.outputs.frontend-status }} | ${{ steps.collect-results.outputs.frontend-details }} |
            
            ### 📋 Coverage Reports
            - 📊 **Backend Coverage**: [Download Report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
            - 📊 **Frontend Coverage**: [Download Report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
            
            > 💡 **Tip**: Click on the individual job details in the [Actions tab](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}) to see detailed test results for each project.
            
            ---
            *Updated at: ${new Date().toISOString()}*`;
            
            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: body
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body
              });
            }
          } catch (error) {
            console.log('Could not comment on PR due to permissions. Results available in job summary.');
            console.log('Error:', error.message);
          } 
